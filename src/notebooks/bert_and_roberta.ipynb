{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiLDBLU36pBG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "id": "B0iqx_LwbDA3",
        "outputId": "e1b4bd79-b28f-4db9-ebe6-61318d81f593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.8/dist-packages (0.3.25)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from jax) (4.4.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax) (1.21.6)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5f37ccd91860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bbc_train.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bbc_train.csv'"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install jax\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "bert_checkpoint = 'bert-base-cased'\n",
        "roberta_checkpoint = 'roberta-base'\n",
        "\n",
        "checkpoint = bert_checkpoint\n",
        "\n",
        "datapath = \"bbc_train.csv\"\n",
        "df = pd.read_csv(datapath)\n",
        "df.groupby(['category']).size().plot.bar()\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "labels = {'business':0,\n",
        "          'sport':1,\n",
        "          'politics':2\n",
        "          # 'entertainment':3,\n",
        "          # 'tech':4,\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZKJQkKA87rt"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jQmrfsmqgfl"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['category']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 256, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFT7hscwN3_3"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pecW3opo6k3"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel, AutoModelForSequenceClassification\n",
        "from torch import nn\n",
        "#import evaluate as metric_evaluate\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.classification import MulticlassF1Score, MulticlassROC, MulticlassAUROC, MulticlassRecall\n",
        "\n",
        "class TextClassifier(nn.Module): \n",
        "\n",
        "    def __init__(self, checkpoint, num_of_classes, dropout=0.5):\n",
        "\n",
        "        super(TextClassifier, self).__init__()\n",
        "\n",
        "        self.bert = AutoModelForSequenceClassification.from_pretrained(checkpoint,\n",
        "                                                                     num_labels=num_of_classes)\n",
        "        self.num_of_labels = num_of_classes\n",
        "\n",
        "    def forward(self, input_id, mask, labels):\n",
        "\n",
        "        pooled_output = self.bert(input_ids= input_id, attention_mask=mask,\n",
        "                                  labels=labels, return_dict=True)\n",
        "\n",
        "        return pooled_output\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs, train_batch_size, val_batch_size):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=train_batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=val_batch_size)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "            total_auc_train = 0\n",
        "            total_recall_train = 0\n",
        "            total_precision_train = 0\n",
        "            total_f1_train = 0\n",
        "            # total_fpr_train = 0\n",
        "            # total_tpr_train = 0\n",
        "            # total_thresholds_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, train_label)\n",
        "                #print(f\"\\n output:{output} \\n\")\n",
        "                \n",
        "                probabilities = F.softmax(output.logits, dim=1)\n",
        "                #print(f\"probabilities: {probabilities}\")\n",
        "\n",
        "                loss = criterion(probabilities, train_label.long())\n",
        "                #print(f\"loss: {loss}\")\n",
        "\n",
        "                (predictions, predictions_indicies) = torch.max(probabilities,dim=1)\n",
        "\n",
        "                # print(f\"predictions: {predictions}\")\n",
        "                # print(f\"train_label: {train_label}\")\n",
        "\n",
        "                metric_auc = MulticlassAUROC(predictions, train_label, reorder=True)\n",
        "                # print(f\"metric_auc: {metric_auc}\")\n",
        "\n",
        "                metric_precision_recall = MulticlassRecall(preds=probabilities, target=train_label,num_classes=model.num_of_labels)\n",
        "                precision, recall = metric_precision_recall[0], metric_precision_recall[1]\n",
        "                # print(f\"\\nprecision: {precision}\\n\")\n",
        "                # print(f\"recall: {recall}\\n\")\n",
        "\n",
        "                metric_f1 = MulticlassF1Score(num_classes=model.num_of_labels).to(device)\n",
        "                f1 = metric_f1(predictions, train_label)\n",
        "                #print(f\"f1: {f1}\\n\")\n",
        "\n",
        "                # metric_roc = MulticlassROC(num_classes=5)\n",
        "                # fpr_tpr_thresholds_tuple = metric_roc(probabilities, train_label)\n",
        "                # print(f\"fpr: {fpr_tpr_thresholds_tuple[0]}\\n\")\n",
        "                # print(f\"tpr: {fpr_tpr_thresholds_tuple[1]}\\n\")\n",
        "                # print(f\"thresholds: {fpr_tpr_thresholds_tuple[2]}\\n\")\n",
        "\n",
        "                total_loss_train += loss\n",
        "              \n",
        "                acc = (predictions_indicies == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                total_auc_train += metric_auc\n",
        "                total_recall_train += recall\n",
        "                total_precision_train += precision\n",
        "                total_f1_train += f1\n",
        "                # total_fpr_train += fpr_tpr_thresholds_tuple[0]\n",
        "                # total_tpr_train += fpr_tpr_thresholds_tuple[1]\n",
        "                #total_thresholds_train += fpr_tpr_thresholds_tuple[3]\n",
        "\n",
        "                model.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "            total_recall_val = 0\n",
        "            total_precision_val = 0\n",
        "            total_f1_val = 0\n",
        "            total_auc_val = 0\n",
        "            # total_fpr_val = 0\n",
        "            # total_tpr_val = 0\n",
        "            # total_thresholds_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask, val_label)\n",
        "                    #batch_loss = criterion(output, val_label.long())\n",
        "                    #total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    probabilities = F.softmax(output.logits, dim=1)\n",
        "\n",
        "                    loss = criterion(probabilities, val_label.long())\n",
        "                    #print(f\"loss: {loss}\")\n",
        "\n",
        "                    (predictions, predictions_indicies) = torch.max(probabilities,dim=1)\n",
        "\n",
        "                    # print(f\"predictions: {predictions}\")\n",
        "                    # print(f\"train_label: {train_label}\")\n",
        "\n",
        "                    metric_auc = MulticlassAUROC(predictions, val_label, reorder=True)\n",
        "                    # print(f\"metric_auc: {metric_auc}\")\n",
        "\n",
        "                    metric_precision_recall = MulticlassRecall(preds=probabilities, target=val_label,num_classes=model.num_of_labels)\n",
        "                    precision, recall = metric_precision_recall[0], metric_precision_recall[1]\n",
        "                    # print(f\"\\nprecision: {precision}\\n\")\n",
        "                    # print(f\"recall: {recall}\\n\")\n",
        "\n",
        "                    metric_f1 = MulticlassF1Score(num_classes=model.num_of_labels).to(device)\n",
        "                    f1 = metric_f1(predictions, val_label)\n",
        "                    #print(f\"f1: {f1}\\n\")\n",
        "\n",
        "                    # metric_roc = MulticlassROC(num_classes=5)\n",
        "                    # fpr_tpr_thresholds_tuple = metric_roc(probabilities, train_label)\n",
        "                    # print(f\"fpr: {fpr_tpr_thresholds_tuple[0]}\\n\")\n",
        "                    # print(f\"tpr: {fpr_tpr_thresholds_tuple[1]}\\n\")\n",
        "                    # print(f\"thresholds: {fpr_tpr_thresholds_tuple[2]}\\n\")\n",
        "\n",
        "                    total_loss_val += loss\n",
        "                  \n",
        "                    acc = (predictions_indicies == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "\n",
        "                    total_auc_val += metric_auc\n",
        "                    total_recall_val += recall\n",
        "                    total_precision_val += precision\n",
        "                    total_f1_val += f1\n",
        "\n",
        "            print(f\"Epochs: {epoch_num + 1} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Recall: {total_recall_train / len(train_data): .3f} | Train Precision: {total_precision_train / len(train_data): .3f} | Train F1-Score: {total_f1_train / len(train_data): .3f} | Train AUC: {total_auc_train/ len(train_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | TraValin Recall: {total_recall_val / len(val_data): .3f} | Val Precision: {total_precision_val / len(val_data): .3f} | Val F1-Score: {total_f1_val / len(val_data): .3f} | Val AUC: {total_auc_val/ len(val_data): .3f}\")\n",
        "                  \n",
        "def evaluate(model, test_data, test_batch_size):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=test_batch_size)\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    #total_loss_test = 0\n",
        "    total_auc_test = 0\n",
        "    total_recall_test = 0\n",
        "    total_precision_test = 0\n",
        "    total_f1_test = 0\n",
        "\n",
        "    probabilities_list = []\n",
        "    logits_list = []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask, test_label)\n",
        "              #batch_loss = criterion(output, val_label.long())\n",
        "              #total_loss_val += batch_loss.item()\n",
        "              \n",
        "              logits_list.append(output.logits)\n",
        "              probabilities = F.softmax(output.logits, dim=1)\n",
        "              probabilities_list.append(probabilities)\n",
        "              #loss = criterion(probabilities, test_label.long())\n",
        "              #print(f\"loss: {loss}\")\n",
        "\n",
        "              (predictions, predictions_indicies) = torch.max(probabilities,dim=1)\n",
        "\n",
        "              # print(f\"predictions: {predictions}\")\n",
        "              # print(f\"train_label: {train_label}\")\n",
        "\n",
        "              metric_auc = MulticlassAUROC(predictions, test_label, reorder=True)\n",
        "              # print(f\"metric_auc: {metric_auc}\")\n",
        "\n",
        "              metric_precision_recall = MulticlassRecall(preds=probabilities, target=test_label,num_classes=model.num_of_labels)\n",
        "              precision, recall = metric_precision_recall[0], metric_precision_recall[1]\n",
        "              # print(f\"\\nprecision: {precision}\\n\")\n",
        "              # print(f\"recall: {recall}\\n\")\n",
        "\n",
        "              metric_f1 = MulticlassF1Score(num_classes=model.num_of_labels).to(device)\n",
        "              f1 = metric_f1(predictions, test_label)\n",
        "              #print(f\"f1: {f1}\\n\")\n",
        "\n",
        "              # metric_roc = MulticlassROC(num_classes=5)\n",
        "              # fpr_tpr_thresholds_tuple = metric_roc(probabilities, train_label)\n",
        "              # print(f\"fpr: {fpr_tpr_thresholds_tuple[0]}\\n\")\n",
        "              # print(f\"tpr: {fpr_tpr_thresholds_tuple[1]}\\n\")\n",
        "              # print(f\"thresholds: {fpr_tpr_thresholds_tuple[2]}\\n\")\n",
        "\n",
        "              #total_loss_val += loss\n",
        "\n",
        "              acc = (predictions_indicies == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "\n",
        "              total_auc_test += metric_auc\n",
        "              total_recall_test += recall\n",
        "              total_precision_test += precision\n",
        "              total_f1_test += f1\n",
        "  \n",
        "    print(f\"Test Accuracy: {total_acc_test / len(test_data): .3f} | Test Recall: {total_recall_test / len(test_data): .3f} | Test Precision: {total_precision_test / len(test_data): .3f} | Test F1-Score: {total_f1_test / len(test_data): .3f} | Test AUC: {total_auc_test/ len(test_data): .3f}\")\n",
        "    return probabilities_list, logits_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVJrQ_uJKfVc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train), len(df_val), len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quVJK_YPKheS"
      },
      "outputs": [],
      "source": [
        "num_of_classes=3\n",
        "model = TextClassifier(checkpoint, num_of_classes=num_of_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fE2LX_IGhVb"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1\n",
        "LR = 1e-6\n",
        "train_batch_size = 2\n",
        "val_batch_size = 2\n",
        "\n",
        "train(model, df_train, df_val, LR, EPOCHS, train_batch_size, val_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKIL-imZFrff"
      },
      "outputs": [],
      "source": [
        "test_batch_size = 12\n",
        "probabilities_list = evaluate(model, df_test, test_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2_cb0r56f8X"
      },
      "outputs": [],
      "source": [
        "probabilities_list, logits_list = evaluate(model, df_test, test_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYigMMKz8q9z"
      },
      "outputs": [],
      "source": [
        "probabilities_list_file = 'probabilities_list_file.txt'\n",
        "with open(probabilities_list_file) as f:\n",
        "  for elem in probabilities_list:\n",
        "    f.write(elem+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_list_file = 'logits_list_file.txt'\n",
        "with open(logits_list_file) as f:\n",
        "  for elem in logits_list:\n",
        "    f.write(elem+\"\\n\")"
      ],
      "metadata": {
        "id": "ASOCktXwECUU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}